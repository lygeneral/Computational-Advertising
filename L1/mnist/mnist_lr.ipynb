{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "uuid": "bef8ebe5-b72c-4618-89fd-8b7c1316121d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1797, 64)\n",
      "[[ 0.  0.  5. 13.  9.  1.  0.  0.]\n",
      " [ 0.  0. 13. 15. 10. 15.  5.  0.]\n",
      " [ 0.  3. 15.  2.  0. 11.  8.  0.]\n",
      " [ 0.  4. 12.  0.  0.  8.  8.  0.]\n",
      " [ 0.  5.  8.  0.  0.  9.  8.  0.]\n",
      " [ 0.  4. 11.  0.  1. 12.  7.  0.]\n",
      " [ 0.  2. 14.  5. 10. 12.  0.  0.]\n",
      " [ 0.  0.  6. 13. 10.  0.  0.  0.]]\n",
      "0\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "# 使用LR进行MNIST手写数字分类\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import preprocessing\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.datasets import load_digits\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# 加载数据\n",
    "digits = load_digits()\n",
    "data = digits.data\n",
    "# 数据探索\n",
    "print(data.shape)\n",
    "# 查看第一幅图像\n",
    "print(digits.images[0])\n",
    "# 第一幅图像代表的数字含义\n",
    "print(digits.target[0])\n",
    "# 将第一幅图像显示出来\n",
    "plt.gray()\n",
    "plt.title('Handwritten Digits')\n",
    "plt.imshow(digits.images[0])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[1;31mInit signature:\u001b[0m\n",
       "\u001b[0mLogisticRegression\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mpenalty\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'l2'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mdual\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mtol\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.0001\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mC\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1.0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mfit_intercept\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mintercept_scaling\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mclass_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mrandom_state\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0msolver\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'warn'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mmax_iter\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m100\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mmulti_class\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'warn'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mwarm_start\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mn_jobs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
       "\u001b[1;31mDocstring:\u001b[0m     \n",
       "Logistic Regression (aka logit, MaxEnt) classifier.\n",
       "\n",
       "In the multiclass case, the training algorithm uses the one-vs-rest (OvR)\n",
       "scheme if the 'multi_class' option is set to 'ovr', and uses the cross-\n",
       "entropy loss if the 'multi_class' option is set to 'multinomial'.\n",
       "(Currently the 'multinomial' option is supported only by the 'lbfgs',\n",
       "'sag' and 'newton-cg' solvers.)\n",
       "\n",
       "This class implements regularized logistic regression using the\n",
       "'liblinear' library, 'newton-cg', 'sag' and 'lbfgs' solvers. It can handle\n",
       "both dense and sparse input. Use C-ordered arrays or CSR matrices\n",
       "containing 64-bit floats for optimal performance; any other input format\n",
       "will be converted (and copied).\n",
       "\n",
       "The 'newton-cg', 'sag', and 'lbfgs' solvers support only L2 regularization\n",
       "with primal formulation. The 'liblinear' solver supports both L1 and L2\n",
       "regularization, with a dual formulation only for the L2 penalty.\n",
       "\n",
       "Read more in the :ref:`User Guide <logistic_regression>`.\n",
       "\n",
       "Parameters\n",
       "----------\n",
       "penalty : str, 'l1' or 'l2', default: 'l2'\n",
       "    Used to specify the norm used in the penalization. The 'newton-cg',\n",
       "    'sag' and 'lbfgs' solvers support only l2 penalties.\n",
       "\n",
       "    .. versionadded:: 0.19\n",
       "       l1 penalty with SAGA solver (allowing 'multinomial' + L1)\n",
       "\n",
       "dual : bool, default: False\n",
       "    Dual or primal formulation. Dual formulation is only implemented for\n",
       "    l2 penalty with liblinear solver. Prefer dual=False when\n",
       "    n_samples > n_features.\n",
       "\n",
       "tol : float, default: 1e-4\n",
       "    Tolerance for stopping criteria.\n",
       "\n",
       "C : float, default: 1.0\n",
       "    Inverse of regularization strength; must be a positive float.\n",
       "    Like in support vector machines, smaller values specify stronger\n",
       "    regularization.\n",
       "\n",
       "fit_intercept : bool, default: True\n",
       "    Specifies if a constant (a.k.a. bias or intercept) should be\n",
       "    added to the decision function.\n",
       "\n",
       "intercept_scaling : float, default 1.\n",
       "    Useful only when the solver 'liblinear' is used\n",
       "    and self.fit_intercept is set to True. In this case, x becomes\n",
       "    [x, self.intercept_scaling],\n",
       "    i.e. a \"synthetic\" feature with constant value equal to\n",
       "    intercept_scaling is appended to the instance vector.\n",
       "    The intercept becomes ``intercept_scaling * synthetic_feature_weight``.\n",
       "\n",
       "    Note! the synthetic feature weight is subject to l1/l2 regularization\n",
       "    as all other features.\n",
       "    To lessen the effect of regularization on synthetic feature weight\n",
       "    (and therefore on the intercept) intercept_scaling has to be increased.\n",
       "\n",
       "class_weight : dict or 'balanced', default: None\n",
       "    Weights associated with classes in the form ``{class_label: weight}``.\n",
       "    If not given, all classes are supposed to have weight one.\n",
       "\n",
       "    The \"balanced\" mode uses the values of y to automatically adjust\n",
       "    weights inversely proportional to class frequencies in the input data\n",
       "    as ``n_samples / (n_classes * np.bincount(y))``.\n",
       "\n",
       "    Note that these weights will be multiplied with sample_weight (passed\n",
       "    through the fit method) if sample_weight is specified.\n",
       "\n",
       "    .. versionadded:: 0.17\n",
       "       *class_weight='balanced'*\n",
       "\n",
       "random_state : int, RandomState instance or None, optional, default: None\n",
       "    The seed of the pseudo random number generator to use when shuffling\n",
       "    the data.  If int, random_state is the seed used by the random number\n",
       "    generator; If RandomState instance, random_state is the random number\n",
       "    generator; If None, the random number generator is the RandomState\n",
       "    instance used by `np.random`. Used when ``solver`` == 'sag' or\n",
       "    'liblinear'.\n",
       "\n",
       "solver : str, {'newton-cg', 'lbfgs', 'liblinear', 'sag', 'saga'},              default: 'liblinear'.\n",
       "\n",
       "    Algorithm to use in the optimization problem.\n",
       "\n",
       "    - For small datasets, 'liblinear' is a good choice, whereas 'sag' and\n",
       "      'saga' are faster for large ones.\n",
       "    - For multiclass problems, only 'newton-cg', 'sag', 'saga' and 'lbfgs'\n",
       "      handle multinomial loss; 'liblinear' is limited to one-versus-rest\n",
       "      schemes.\n",
       "    - 'newton-cg', 'lbfgs' and 'sag' only handle L2 penalty, whereas\n",
       "      'liblinear' and 'saga' handle L1 penalty.\n",
       "\n",
       "    Note that 'sag' and 'saga' fast convergence is only guaranteed on\n",
       "    features with approximately the same scale. You can\n",
       "    preprocess the data with a scaler from sklearn.preprocessing.\n",
       "\n",
       "    .. versionadded:: 0.17\n",
       "       Stochastic Average Gradient descent solver.\n",
       "    .. versionadded:: 0.19\n",
       "       SAGA solver.\n",
       "    .. versionchanged:: 0.20\n",
       "        Default will change from 'liblinear' to 'lbfgs' in 0.22.\n",
       "\n",
       "max_iter : int, default: 100\n",
       "    Useful only for the newton-cg, sag and lbfgs solvers.\n",
       "    Maximum number of iterations taken for the solvers to converge.\n",
       "\n",
       "multi_class : str, {'ovr', 'multinomial', 'auto'}, default: 'ovr'\n",
       "    If the option chosen is 'ovr', then a binary problem is fit for each\n",
       "    label. For 'multinomial' the loss minimised is the multinomial loss fit\n",
       "    across the entire probability distribution, *even when the data is\n",
       "    binary*. 'multinomial' is unavailable when solver='liblinear'.\n",
       "    'auto' selects 'ovr' if the data is binary, or if solver='liblinear',\n",
       "    and otherwise selects 'multinomial'.\n",
       "\n",
       "    .. versionadded:: 0.18\n",
       "       Stochastic Average Gradient descent solver for 'multinomial' case.\n",
       "    .. versionchanged:: 0.20\n",
       "        Default will change from 'ovr' to 'auto' in 0.22.\n",
       "\n",
       "verbose : int, default: 0\n",
       "    For the liblinear and lbfgs solvers set verbose to any positive\n",
       "    number for verbosity.\n",
       "\n",
       "warm_start : bool, default: False\n",
       "    When set to True, reuse the solution of the previous call to fit as\n",
       "    initialization, otherwise, just erase the previous solution.\n",
       "    Useless for liblinear solver. See :term:`the Glossary <warm_start>`.\n",
       "\n",
       "    .. versionadded:: 0.17\n",
       "       *warm_start* to support *lbfgs*, *newton-cg*, *sag*, *saga* solvers.\n",
       "\n",
       "n_jobs : int or None, optional (default=None)\n",
       "    Number of CPU cores used when parallelizing over classes if\n",
       "    multi_class='ovr'\". This parameter is ignored when the ``solver`` is\n",
       "    set to 'liblinear' regardless of whether 'multi_class' is specified or\n",
       "    not. ``None`` means 1 unless in a :obj:`joblib.parallel_backend`\n",
       "    context. ``-1`` means using all processors.\n",
       "    See :term:`Glossary <n_jobs>` for more details.\n",
       "\n",
       "Attributes\n",
       "----------\n",
       "\n",
       "classes_ : array, shape (n_classes, )\n",
       "    A list of class labels known to the classifier.\n",
       "\n",
       "coef_ : array, shape (1, n_features) or (n_classes, n_features)\n",
       "    Coefficient of the features in the decision function.\n",
       "\n",
       "    `coef_` is of shape (1, n_features) when the given problem is binary.\n",
       "    In particular, when `multi_class='multinomial'`, `coef_` corresponds\n",
       "    to outcome 1 (True) and `-coef_` corresponds to outcome 0 (False).\n",
       "\n",
       "intercept_ : array, shape (1,) or (n_classes,)\n",
       "    Intercept (a.k.a. bias) added to the decision function.\n",
       "\n",
       "    If `fit_intercept` is set to False, the intercept is set to zero.\n",
       "    `intercept_` is of shape (1,) when the given problem is binary.\n",
       "    In particular, when `multi_class='multinomial'`, `intercept_`\n",
       "    corresponds to outcome 1 (True) and `-intercept_` corresponds to\n",
       "    outcome 0 (False).\n",
       "\n",
       "n_iter_ : array, shape (n_classes,) or (1, )\n",
       "    Actual number of iterations for all classes. If binary or multinomial,\n",
       "    it returns only 1 element. For liblinear solver, only the maximum\n",
       "    number of iteration across all classes is given.\n",
       "\n",
       "    .. versionchanged:: 0.20\n",
       "\n",
       "        In SciPy <= 1.0.0 the number of lbfgs iterations may exceed\n",
       "        ``max_iter``. ``n_iter_`` will now report at most ``max_iter``.\n",
       "\n",
       "Examples\n",
       "--------\n",
       ">>> from sklearn.datasets import load_iris\n",
       ">>> from sklearn.linear_model import LogisticRegression\n",
       ">>> X, y = load_iris(return_X_y=True)\n",
       ">>> clf = LogisticRegression(random_state=0, solver='lbfgs',\n",
       "...                          multi_class='multinomial').fit(X, y)\n",
       ">>> clf.predict(X[:2, :])\n",
       "array([0, 0])\n",
       ">>> clf.predict_proba(X[:2, :]) # doctest: +ELLIPSIS\n",
       "array([[9.8...e-01, 1.8...e-02, 1.4...e-08],\n",
       "       [9.7...e-01, 2.8...e-02, ...e-08]])\n",
       ">>> clf.score(X, y)\n",
       "0.97...\n",
       "\n",
       "See also\n",
       "--------\n",
       "SGDClassifier : incrementally trained logistic regression (when given\n",
       "    the parameter ``loss=\"log\"``).\n",
       "LogisticRegressionCV : Logistic regression with built-in cross validation\n",
       "\n",
       "Notes\n",
       "-----\n",
       "The underlying C implementation uses a random number generator to\n",
       "select features when fitting the model. It is thus not uncommon,\n",
       "to have slightly different results for the same input data. If\n",
       "that happens, try with a smaller tol parameter.\n",
       "\n",
       "Predict output may not match that of standalone liblinear in certain\n",
       "cases. See :ref:`differences from liblinear <liblinear_differences>`\n",
       "in the narrative documentation.\n",
       "\n",
       "References\n",
       "----------\n",
       "\n",
       "LIBLINEAR -- A Library for Large Linear Classification\n",
       "    https://www.csie.ntu.edu.tw/~cjlin/liblinear/\n",
       "\n",
       "SAG -- Mark Schmidt, Nicolas Le Roux, and Francis Bach\n",
       "    Minimizing Finite Sums with the Stochastic Average Gradient\n",
       "    https://hal.inria.fr/hal-00860051/document\n",
       "\n",
       "SAGA -- Defazio, A., Bach F. & Lacoste-Julien S. (2014).\n",
       "    SAGA: A Fast Incremental Gradient Method With Support\n",
       "    for Non-Strongly Convex Composite Objectives\n",
       "    https://arxiv.org/abs/1407.0202\n",
       "\n",
       "Hsiang-Fu Yu, Fang-Lan Huang, Chih-Jen Lin (2011). Dual coordinate descent\n",
       "    methods for logistic regression and maximum entropy models.\n",
       "    Machine Learning 85(1-2):41-75.\n",
       "    https://www.csie.ntu.edu.tw/~cjlin/papers/maxent_dual.pdf\n",
       "\u001b[1;31mFile:\u001b[0m           c:\\programdata\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py\n",
       "\u001b[1;31mType:\u001b[0m           type\n",
       "\u001b[1;31mSubclasses:\u001b[0m     LogisticRegressionCV\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "LogisticRegression?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "uuid": "9c3af58a-2fca-460b-abe5-9228b40e9fa1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR准确率: 0.9600\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:460: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "# 分割数据，将25%的数据作为测试集，其余作为训练集\n",
    "train_x, test_x, train_y, test_y = train_test_split(data, digits.target, test_size=0.25, random_state=33)\n",
    "\n",
    "# 采用Z-Score规范化\n",
    "ss = preprocessing.StandardScaler()\n",
    "train_ss_x = ss.fit_transform(train_x)\n",
    "test_ss_x = ss.transform(test_x)\n",
    "\n",
    "# 创建LR分类器\n",
    "lr = LogisticRegression()\n",
    "lr.fit(train_ss_x, train_y)\n",
    "predict_y=lr.predict(test_ss_x)\n",
    "print('LR准确率: %0.4lf' % accuracy_score(predict_y, test_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "uuid": "f17ed425-f5c4-4f9f-88c0-12d3dc01b319"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
